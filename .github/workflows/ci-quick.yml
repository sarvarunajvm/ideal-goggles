# Quick CI Workflow - Optimized Parallel Execution
# Purpose: Run on every PR for fast feedback + push to main for release CI checks
# Scope:
#   - Code quality: linting, type checking, and formatting
#   - All unit tests (frontend & backend) with coverage
#   - Coverage upload to Codecov and PR comments
#   - P0 critical E2E tests (essential application health checks)
# Time: ~10-12 minutes (optimized parallel execution)

name: Quick CI

permissions:
  contents: read
  issues: write
  pull-requests: write

on:
  # On push to main branches (needed for release workflow CI checks)
  push:
    branches: [ main, develop ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/workflows/e2e.yml'

  # On pull requests
  pull_request:
    types: [opened, synchronize]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/workflows/e2e.yml'

jobs:
  # Job 1: Code Quality Checks (Fast - ~3 minutes)
  quality-checks:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 8

    steps:
    - uses: actions/checkout@v4

    - name: Install pnpm
      uses: pnpm/action-setup@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'

    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.pnpm-store
        key: ${{ runner.os }}-deps-${{ hashFiles('**/package.json', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-deps-

    - name: Install dependencies
      run: |
        # Install all dependencies using the unified script
        pnpm run install:all

    - name: Code Quality Checks
      run: |
        # Use standardized package.json scripts
        pnpm run lint:all
        pnpm run typecheck:all
        pnpm run format:all

    - name: Check file sizes
      run: |
        echo "### ðŸ“¦ File Size Check" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Large files (>1MB):" >> $GITHUB_STEP_SUMMARY
        find . -type f -size +1M -not -path "./node_modules/*" -not -path "./.git/*" -not -path "./dist*/*" -exec ls -lh {} \; | head -20 >> $GITHUB_STEP_SUMMARY || echo "No large files found âœ…" >> $GITHUB_STEP_SUMMARY

  # Job 2: Backend Tests & Coverage (Parallel - ~8 minutes)
  backend-tests:
    name: Backend Tests & Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 10

    strategy:
      matrix:
        python-version: ['3.12']

    steps:
    - uses: actions/checkout@v4

    - name: Install pnpm
      uses: pnpm/action-setup@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.pnpm-store
        key: ${{ runner.os }}-deps-${{ hashFiles('**/package.json', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-deps-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y tesseract-ocr tesseract-ocr-eng

    - name: Install backend dependencies
      run: |
        pnpm run backend:install

    - name: Run all backend tests with coverage
      run: |
        # Use standardized package.json script for backend coverage
        pnpm run backend:coverage || true
      continue-on-error: true

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./backend/coverage.xml
        flags: backend
        name: backend-coverage
        fail_ci_if_error: false

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: backend-test-results-${{ matrix.python-version }}
        path: |
          backend/test-results-*.xml
          backend/htmlcov/
          backend/coverage.xml

  # Job 3: Frontend Tests & Coverage (Parallel - ~6 minutes)
  frontend-tests:
    name: Frontend Tests & Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 8

    strategy:
      matrix:
        node-version: ['20']

    steps:
    - uses: actions/checkout@v4

    - name: Install pnpm
      uses: pnpm/action-setup@v4

    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        registry-url: 'https://registry.npmjs.org/'

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.pnpm-store
        key: ${{ runner.os }}-deps-${{ hashFiles('**/package.json', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-deps-

    - name: Install dependencies
      run: |
        pnpm install --no-frozen-lockfile

    - name: Run all frontend tests with coverage
      run: |
        # Run all frontend tests including unit and integration
        pnpm run test:coverage || true
      continue-on-error: true
      env:
        JEST_JUNIT_OUTPUT_DIR: ./test-results
        JEST_JUNIT_OUTPUT_NAME: junit-${{ matrix.node-version }}.xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage
        fail_ci_if_error: false

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: frontend-test-results-${{ matrix.node-version }}
        path: |
          frontend/test-results/
          frontend/coverage/

  # Job 4: P0 Critical E2E Tests (Parallel - ~5 minutes)
  p0-e2e-tests:
    name: P0 Critical E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 8

    steps:
    - uses: actions/checkout@v4

    - name: Install pnpm
      uses: pnpm/action-setup@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'

    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.pnpm-store
          ~/.cache/ms-playwright
        key: ${{ runner.os }}-deps-${{ hashFiles('**/package.json', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-deps-

    - name: Install dependencies and Playwright
      run: |
        # Install all dependencies
        pnpm run install:all
        # Install Playwright browsers
        cd func_tests
        pnpm install --no-frozen-lockfile
        pnpm exec playwright install chromium

    - name: Quick smoke test
      run: |
        # Just verify imports work
        cd backend
        python -c "from src.main import app; print('âœ… Backend imports OK')"
        cd ..

        # Check frontend build config
        npx vite build --config frontend/vite.config.ts --mode production --logLevel silent --outDir temp-build || echo "Build config check completed"
        rm -rf temp-build

    - name: Run P0 Critical E2E Tests
      run: |
        # Run only P0 critical tests (fastest essential checks)
        if [ -f "func_tests/e2e/00-p0-critical.test.ts" ]; then
          echo "Running P0 critical tests..."
          pnpm run e2e:p0 || echo "P0 tests completed with warnings"
        else
          echo "P0 critical test suite not found, skipping..."
        fi

    - name: Upload P0 test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: p0-e2e-results
        path: |
          func_tests/test-results/
          func_tests/playwright-report/
        retention-days: 1

  # Job 5: Comment on PR with test results (Waits for all jobs)
  comment-on-pr:
    name: Comment Test Results on PR
    runs-on: ubuntu-latest
    needs: [quality-checks, backend-tests, frontend-tests, p0-e2e-tests]
    permissions:
      contents: read
      issues: write
      pull-requests: write
    if: |
      always() &&
      github.event_name == 'pull_request' &&
      github.event.pull_request.head.repo.full_name == github.repository

    steps:
    - name: Download test results
      uses: actions/download-artifact@v4
      with:
        path: test-results

    - name: Create test summary comment
      uses: actions/github-script@v7
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        script: |
          const fs = require('fs');

          let comment = '## ðŸš€ Quick CI Results\\n\\n';
          comment += `ðŸ”¨ **Build:** #${{ github.run_number }} | `;
          comment += `âš¡ **Triggered by:** ${{ github.actor }}\\n\\n`;

          comment += '### Test Results\\n\\n';
          comment += '| Component | Status | Details |\\n';
          comment += '|-----------|--------|---------|\\n';

          // Quality checks
          const qualityStatus = '${{ needs.quality-checks.result }}';
          const qualityIcon = qualityStatus === 'success' ? 'âœ…' : qualityStatus === 'failure' ? 'âŒ' : 'â­ï¸';
          comment += `| ðŸ” Code Quality | ${qualityIcon} | Lint, TypeCheck, Format |\\n`;

          // Backend results
          const backendStatus = '${{ needs.backend-tests.result }}';
          const backendIcon = backendStatus === 'success' ? 'âœ…' : backendStatus === 'failure' ? 'âŒ' : 'â­ï¸';
          comment += `| ðŸ Backend Tests | ${backendIcon} | Unit tests with coverage |\\n`;

          // Frontend results
          const frontendStatus = '${{ needs.frontend-tests.result }}';
          const frontendIcon = frontendStatus === 'success' ? 'âœ…' : frontendStatus === 'failure' ? 'âŒ' : 'â­ï¸';
          comment += `| âš›ï¸ Frontend Tests | ${frontendIcon} | Unit tests with coverage |\\n`;

          // P0 E2E results
          const p0Status = '${{ needs.p0-e2e-tests.result }}';
          const p0Icon = p0Status === 'success' ? 'âœ…' : p0Status === 'failure' ? 'âŒ' : 'â­ï¸';
          comment += `| ðŸŽ­ P0 E2E Tests | ${p0Icon} | Critical user flows |\\n`;

          comment += '\\n### ðŸ“Š Coverage\\n';
          comment += '- Coverage reports uploaded to [Codecov](https://codecov.io/gh/${{ github.repository }})\\n';
          comment += '- View detailed reports in workflow artifacts\\n';
          comment += `- Generated at: ${new Date().toISOString()}\\n`;

          comment += '\\n### âš¡ Performance\\n';
          comment += '- All jobs ran in parallel for faster feedback\\n';
          comment += '- Full E2E test suite runs in dedicated workflow\\n';

          // Find and update or create comment
          const token = process.env.GITHUB_TOKEN;
          if (!token) {
            core.warning('Missing GITHUB_TOKEN; skipping PR comment.');
            return;
          }

          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const botComment = comments.find(comment =>
            comment.user.type === 'Bot' &&
            comment.body.includes('ðŸš€ Quick CI Results')
          );

          if (botComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: comment
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });
          }
